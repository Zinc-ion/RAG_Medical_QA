import streamlit as st
import ollama
import py2neo
import random
import re
import os
import sys
import logging
import networkx as nx
from pyvis.network import Network
import streamlit.components.v1 as components

#lightragPkg
from LightRAG.lightragPkg.lightrag import LightRAG, QueryParam
from LightRAG.lightragPkg.llm.zhipu import zhipu_complete
from LightRAG.lightragPkg.llm.ollama import ollama_embedding
from LightRAG.lightragPkg.utils import EmbeddingFunc

# åŠ è½½ç¯å¢ƒå˜é‡
from dotenv import load_dotenv

# æ·»åŠ LightRAGç›®å½•åˆ°ç³»ç»Ÿè·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), 'LightRAG'))

# åŠ è½½.envæ–‡ä»¶
load_dotenv()

WORKING_DIR = "./dickens"  #å­˜æ”¾æ•°æ®çš„ç›®å½•

logging.basicConfig(format="%(levelname)s:%(message)s", level=logging.INFO)

# --- æ¨¡æ‹ŸåŠ¨æ€æ–°é—»æ•°æ®æµ ---
FAKE_NEWS_DATA = [
    """ã€2024-12-29 çªå‘å«ç”Ÿäº‹ä»¶ã€‘
    æŸåœ°ç–¾æ§ä¸­å¿ƒæŠ¥å‘Šå‘ç°ä¸€ç§æ–°å‹æµæ„Ÿç—…æ¯’å˜å¼‚æ ªâ€œH9N9-Betaâ€ã€‚
    ç—‡çŠ¶è¡¨ç°ï¼šè¯¥å˜å¼‚æ ªé™¤å¸¸è§„æµæ„Ÿç—‡çŠ¶å¤–ï¼Œæ˜¾è‘—ç‰¹å¾ä¸ºæŒç»­æ€§å…³èŠ‚å‰§ç—›å’Œç»“è†œå……è¡€ã€‚
    æ²»ç–—æ–¹æ¡ˆï¼šåˆæ­¥ä¸´åºŠè¯•éªŒæ˜¾ç¤ºï¼ŒæŠ—ç—…æ¯’è¯ç‰©â€œå¥¥å¸ä»–éŸ¦â€è”åˆæ–°è¯â€œV-2024â€å…·æœ‰æ˜¾è‘—ç–—æ•ˆã€‚
    ä¼ æ’­é€”å¾„ï¼šä¸»è¦é€šè¿‡å‘¼å¸é“é£æ²«ä¼ æ’­ï¼Œæ½œä¼æœŸç¼©çŸ­è‡³12å°æ—¶ã€‚""",
    
    """ã€2024-12-30 åŒ»ç–—ç§‘æŠ€è¿›å±•ã€‘
    Zå¤§å­¦é™„å±åŒ»é™¢ç¥ç»å†…ç§‘å›¢é˜Ÿå®£å¸ƒï¼Œâ€œç»é¢…ç£åˆºæ¿€ï¼ˆTMSï¼‰â€åœ¨æ²»ç–—æ…¢æ€§åå¤´ç—›æ–¹é¢å–å¾—çªç ´ã€‚
    ç ”ç©¶è¡¨æ˜ï¼šæ¯å‘¨è¿›è¡Œ3æ¬¡TMSæ²»ç–—ï¼Œé…åˆå£æœå¾®é‡è¤ªé»‘ç´ ï¼Œå¯ä½¿å‘ä½œé¢‘ç‡é™ä½70%ã€‚
    ç¦å¿Œç—‡ï¼šä½“å†…æ¤å…¥å¿ƒè„èµ·æå™¨çš„æ‚£è€…ç¦ç”¨æ­¤ç–—æ³•ã€‚""",
    
    """ã€2024-12-31 è¯å“å¬å›é€šçŸ¥ã€‘
    ç”±äºç”Ÿäº§çº¿é­å—å¾®ç”Ÿç‰©æ±¡æŸ“ï¼ŒXè¯ä¸šé›†å›¢ç´§æ€¥å¬å›æ‰¹æ¬¡å·ä¸º#20241101çš„â€œå¤æ–¹æ„Ÿå†’çµé¢—ç²’â€ã€‚
    é£é™©æç¤ºï¼šæœç”¨å—æ±¡æŸ“è¯å“å¯èƒ½å¯¼è‡´ä¸¥é‡çš„ç»†èŒæ€§è‚ èƒƒç‚ã€‚
    å»ºè®®ï¼šå·²è´­ä¹°è¯¥æ‰¹æ¬¡è¯å“çš„æ‚£è€…è¯·ç«‹å³åœæ­¢æœç”¨ï¼Œå¹¶è”ç³»è¯åº—é€€æ¬¾ã€‚"""
]

@st.cache_resource
def init_rag():
    if not os.path.exists(WORKING_DIR):
        os.mkdir(WORKING_DIR)
    
    api_key = os.environ.get("ZHIPUAI_API_KEY")
    if api_key is None:
        raise Exception("Please set ZHIPU_API_KEY in your environment")
    
    rag = LightRAG(
        working_dir=WORKING_DIR,
        llm_model_func=zhipu_complete,
        llm_model_name="glm-4.7",
        llm_model_max_async=4,
        chunk_token_size=512,
        llm_model_max_token_size=32768,
        embedding_func=EmbeddingFunc(
            embedding_dim=1024,
            max_token_size=8192,
            func=lambda texts: ollama_embedding(
                texts,
                embed_model="quentinz/bge-large-zh-v1.5",
                host="http://localhost:11434",
            )
        ),
    )
    return rag

def visualize_graph(rag_instance, query_entity=None):
    """
    ç”ŸæˆçŸ¥è¯†å›¾è°±çš„å¯è§†åŒ–HTML
    """
    try:
        # å°è¯•è·å–å›¾å¯¹è±¡ï¼Œä¼˜å…ˆä½¿ç”¨å†…å­˜ä¸­çš„ï¼Œå¦åˆ™å°è¯•è¯»å–æ–‡ä»¶
        G = None
        if hasattr(rag_instance, 'chunk_entity_relation_graph'):
            G = rag_instance.chunk_entity_relation_graph
        
        if G is None or len(G.nodes) == 0:
            graph_path = os.path.join(WORKING_DIR, "graph_chunk_entity_relation.graphml")
            if os.path.exists(graph_path):
                G = nx.read_graphml(graph_path)
        
        if G is None or len(G.nodes) == 0:
            return None, "æš‚æ— å›¾è°±æ•°æ®"

        # å­å›¾è¿‡æ»¤é€»è¾‘
        if query_entity:
            # æ¨¡ç³ŠåŒ¹é…èŠ‚ç‚¹ID
            nodes = [n for n in G.nodes() if query_entity in str(n)]
            if nodes:
                # æå–ä¸€è·³é‚»å±…
                subgraph_nodes = set(nodes)
                for n in nodes:
                    subgraph_nodes.update(G.neighbors(n))
                G = G.subgraph(subgraph_nodes)
            else:
                return None, f"æœªæ‰¾åˆ°åŒ…å« '{query_entity}' çš„èŠ‚ç‚¹"
        else:
            # é»˜è®¤åªæ˜¾ç¤ºå‰100ä¸ªèŠ‚ç‚¹ï¼Œé˜²æ­¢æµè§ˆå™¨å¡æ­»
            if len(G.nodes) > 100:
                G = G.subgraph(list(G.nodes())[:100])

        # ä½¿ç”¨ Pyvis ç”Ÿæˆå¯è§†åŒ–
        net = Network(height="500px", width="100%", bgcolor="#222222", font_color="white")
        # é¿å… notebook æ¨¡å¼å¯¼è‡´çš„é—®é¢˜
        net.force_atlas_2based()
        net.from_nx(G)
        
        # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
        path = os.path.join(WORKING_DIR, "temp_graph.html")
        net.save_graph(path)
        
        with open(path, 'r', encoding='utf-8') as f:
            html_string = f.read()
            
        return html_string, "Success"
        
    except Exception as e:
        return None, str(e)

def main(is_admin, usname):
    # åˆå§‹åŒ–RAG (å¸¦ç¼“å­˜)
    rag = init_rag()
    
    st.title(f"åŒ»ç–—æ™ºèƒ½é—®ç­”æœºå™¨äºº (åŸºäºåŠ¨æ€çŸ¥è¯†å›¾è°±)")

    with st.sidebar:
        col1, col2 = st.columns([0.6, 0.6])
        with col1:
            st.image(os.path.join("img", "logo.jpg"), use_container_width=True)

        st.caption(
            f"""<p align="left">æ¬¢è¿æ‚¨ï¼Œ{'ç®¡ç†å‘˜' if is_admin else 'ç”¨æˆ·'}{usname}ï¼</p>""",
            unsafe_allow_html=True,
        )

        # å¯¹è¯çª—å£ç®¡ç†
        if 'chat_windows' not in st.session_state:
            st.session_state.chat_windows = [[]]
            st.session_state.messages = [[]]

        if st.button('æ–°å»ºå¯¹è¯çª—å£'):
            st.session_state.chat_windows.append([])
            st.session_state.messages.append([])

        window_options = [f"å¯¹è¯çª—å£ {i + 1}" for i in range(len(st.session_state.chat_windows))]
        selected_window = st.selectbox('è¯·é€‰æ‹©å¯¹è¯çª—å£:', window_options)
        active_window_index = int(selected_window.split()[1]) - 1

        # --- æ”¹é€ ç‚¹1ï¼šåŠ¨æ€æ›´æ–°æ¨¡å— ---
        st.markdown("---")
        st.subheader("ğŸŒ åŠ¨æ€çŸ¥è¯†æ³¨å…¥ (æ¨¡æ‹Ÿ)")
        st.info("ç”¨äºæ¼”ç¤ºï¼šæ¨¡æ‹Ÿä»æ–°é—»æµä¸­è·å–æœ€æ–°åŒ»ç–—èµ„è®¯å¹¶æ›´æ–°å›¾è°±ã€‚")
        selected_news = st.selectbox("é€‰æ‹©æ¨¡æ‹Ÿæ–°é—»äº‹ä»¶", FAKE_NEWS_DATA)
        
        if st.button("æ³¨å…¥å¹¶æ›´æ–°çŸ¥è¯†åº“"):
            with st.spinner("æ­£åœ¨æŠ½å–å®ä½“å…³ç³»å¹¶æ›´æ–°å›¾è°±..."):
                rag.insert(selected_news)
                st.success("æ›´æ–°æˆåŠŸï¼æ–°çŸ¥è¯†å·²èå…¥å›¾è°±ã€‚")
                # å¼ºåˆ¶åˆ·æ–°å›¾è°±ç¼“å­˜ï¼ˆå¦‚æœæœ‰å¿…è¦ï¼‰
        
        # --- æ”¹é€ ç‚¹2ï¼šå›¾è°±å¯è§†åŒ–å…¥å£ ---
        st.markdown("---")
        st.subheader("ğŸ•¸ï¸ çŸ¥è¯†å›¾è°±å¯è§†åŒ–")
        vis_entity = st.text_input("è¾“å…¥å®ä½“æŸ¥çœ‹å…³è”å­å›¾", placeholder="ç•™ç©ºæŸ¥çœ‹å…¨å±€æ¦‚è§ˆ")
        if st.button("ç”Ÿæˆ/åˆ·æ–°æ‹“æ‰‘å›¾"):
            st.session_state.show_graph = True
            st.session_state.vis_entity = vis_entity

        if st.button("è¿”å›ç™»å½•"):
            st.session_state.logged_in = False
            st.session_state.admin = False
            st.rerun()

    # ä¸»ç•Œé¢é€»è¾‘
    current_messages = st.session_state.messages[active_window_index]

    # æ˜¾ç¤ºå›¾è°± (å¦‚æœè¢«è§¦å‘)
    if st.session_state.get('show_graph', False):
        with st.expander("ğŸ•¸ï¸ å½“å‰çŸ¥è¯†å›¾è°±æ‹“æ‰‘ç»“æ„", expanded=True):
            html_data, msg = visualize_graph(rag, st.session_state.get('vis_entity'))
            if html_data:
                components.html(html_data, height=520, scrolling=True)
            else:
                st.warning(f"å¯è§†åŒ–ç”Ÿæˆå¤±è´¥æˆ–æ— æ•°æ®: {msg}")
            
            if st.button("å…³é—­å›¾è°±"):
                st.session_state.show_graph = False
                st.rerun()

    # æ˜¾ç¤ºå†å²æ¶ˆæ¯
    for message in current_messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # å¤„ç†ç”¨æˆ·è¾“å…¥
    if query := st.chat_input("è¯·è¾“å…¥æ‚¨çš„åŒ»ç–—é—®é¢˜...", key=f"chat_input_{active_window_index}"):
        current_messages.append({"role": "user", "content": query})
        with st.chat_message("user"):
            st.markdown(query)

        response_placeholder = st.empty()
        response_placeholder.text("æ­£åœ¨æ£€ç´¢çŸ¥è¯†å›¾è°±å¹¶ç”Ÿæˆå›ç­”...")

        # RAG æŸ¥è¯¢
        # ä½¿ç”¨ hybrid æ¨¡å¼ä»¥åˆ©ç”¨å›¾è°±å’Œå‘é‡çš„ç»¼åˆä¼˜åŠ¿
        response = rag.query(query, param=QueryParam(mode="hybrid"))
        
        print('ç”Ÿæˆå›ç­”ï¼š', response)
        response_placeholder.empty()

        with st.chat_message("assistant"):
            st.markdown(response)

        current_messages.append({"role": "assistant", "content": response})

    st.session_state.messages[active_window_index] = current_messages
